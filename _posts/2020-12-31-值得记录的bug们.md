---
layout: post
title: 值得记录的bug们
date: 2020-12-31
tag: 持续更新
---



## 值得记录的bug们

## pytorch

#### MSE计算

dataloader的标签（float数值）需要转成float形式。

- eg:

  ``` python
  age_label = item['age_label'].to(device).long()  ## wrong
  age_label = item['age_label'].to(device).float()  ## right
  ```

  


#### debug时，dataloader的num_workers需要设置为0，否则多线程导致无法调试。

#### 数据加载慢：dataloader的**num_workers**需要设置为cpu数量的2倍（大概）



### model 定义：

1. #### `nn.ModuleList` 和 `nn.Sequential` [区别](https://zhuanlan.zhihu.com/p/64990232):

   **nn.ModuleList:** 和python的list相似，具有extend, append等方法，可以把任意 nn.Module 的子类 (比如 nn.Conv2d, nn.Linear 之类的) 加入ModuleList 里面。但不同于一般的 list，加入到 nn.ModuleList 里面的 module 是会自动注册到整个网络上的，同时 module 的 parameters 也会自动添加到整个网络中。【用普通的list则无法将list中的Module加入网络！这些Module中的参数是固定的，不会随着网络优化】。 **通常作用：**将多个模块放在一个列表里，forward的时候可以直接指定索引调用这个列表，而不需要根据具体的模块名来调用。**模型定义的时候不能直接用list，而要用nn.ModuleList([])。**

   **nn.Sequential:** 和nn.ModuleList类似，区别是：已经实现了内部的 forward 函数，而且里面的模块必须是按照顺序进行排列的，所以必须确保前一个模块的输出大小和下一个模块的输入大小是一致的。**通常作用：**组成卷积块 (block)，然后像拼积木一样把不同的 block 拼成整个网络，让代码更简洁，更加结构化。

   ```python
   class net6(nn.Module):
       def __init__(self):
           super(net6, self).__init__()
           self.linears = nn.ModuleList([nn.Linear(10, 10) for i in range(3)])
           #self.linears = [nn.Linear(10, 10) for i in range(3)]   (普通list: 里面的10个线性层并没有加入到net6中，这些层的参数是固定的第一次随机初始化的值，参与前向计算，但不参与后向更新)
       def forward(self, x):
           for layer in self.linears:  
               x = layer(x)
           ## 可以按照顺序使用list中的层，也可以随机使用，比如：
           # x = self.linears[2](x)
           # x = self.linears[0](x) ...
           # 某个模块(eg:self.linears[0])也可以被调用多次，同一个模块对应的这些层是使用同一组 parameters 的，也就是它们的参数是共享的
           return x
       
   class net5(nn.Module):
       def __init__(self):
           super(net5, self).__init__()
           self.block = nn.Sequential(nn.Conv2d(1,20,5),
                                       nn.ReLU(),
                                       nn.Conv2d(20,64,5),
                                       nn.ReLU())
       def forward(self, x):
           x = self.block(x)  ## block内部的forward已经在Sequential里定义过了，直接可以当作一个整体forward
           return x
   ```

2. #### 重复使用同一个模块结构：

   要用几次这个模块，就要定义几次，（如果只定义一次，forward里重复使用，其实用的是相同的一层，参数都是一样的）

   ```python
   ################# 错误示例 #################
   class attrnet(nn.Module):
       def __init__(self, attr_ls):
           super(attrnet, self).__init__()
           self.attr_ls = attr_ls
           self.attr_fc = nn.Linear(512, 1, bias=False)  ## 认为所有的attr使用的fc都是同一个结构，就只定义了一次
       def forward(self, x):
           attr_output_dict = {}
           for attr in self.attr_ls:
               attr_output_dict[attr] = self.attr_fc(x)  
               ## 虽然这里看似每个attr有自己的分支，其实是用的同一个fc，参数和输出都是完全一样的！
           return attr_output_dict
      
   ################# 正确示例 #################
   class attrnet(nn.Module):
       def __init__(self, attr_ls):
           super(attrnet, self).__init__()
           self.attr_ls = attr_ls
           self.attr_fc_ls = nn.ModuleList([nn.Linear(512, 1, bias=False) for _ in self.attr_ls])  
           ## 需要多少个fc，就定义多少个，使用nn.ModuleList()可以简化定义过程
       def forward(self, x):
           attr_output_dict = {}
           for i,attr in enumerate(self.attr_ls):
               attr_output_dict[attr] = self.attr_fc_ls[i](x)  
               ## 每个attr分支使用独立的fc
           return attr_output_dict
   
   ```


###  loss回传

**1. loss回传过程：**

```python
model = MyModel()  ## 定义模型
criterion = nn.CrossEntropyLoss()  ## 定义loss
optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4) ## 定义优化器，这里指定需要优化的参数(后面迭代中会更新的参数)

for epoch in range(1, epochs):
    for i, (inputs, labels) in enumerate(train_loader):
        output= model(inputs)
        loss = criterion(output, labels)
        
        # compute gradient and do SGD step
        optimizer.zero_grad()  ## 先把历史梯度清零 （每次loss回传前都需要，否则会受历史batch的影响）
        loss.backward()   ## loss回传计算各参数的梯度
        optimizer.step()  ## 使用定义的优化器更新参数： W_old - lr*W_grad
```

**2. 相关参数说明：**

**param_groups：**Optimizer类在实例化时会在构造函数中创建一个param_groups列表，列表中有num_groups个长度为6的param_group字典（num_groups取决于你定义optimizer时传入了几组参数），每个param_group包含了 ['params', 'lr', 'momentum', 'dampening', 'weight_decay', 'nesterov'] 这6组键值对。

```python
for g in optimizer.param_groups:  ## 迭代参数组 （数量由模型定义决定，一般有很多组）
    print(g.keys())  ##  ['params', 'lr', 'momentum', 'dampening', 'weight_decay', 'nesterov'] 
    g['lr'] = 0.001  # 临时修改 lr  或其他优化设置
```

**param_group['params']**：由传入的模型参数组成的列表，即实例化Optimizer类时传入该group的参数，如果参数没有分组，则为整个模型的参数model.parameters()，每个参数是一个torch.nn.parameter.Parameter对象

**loss.backward():**PyTorch的反向传播(即tensor.backward())是通过autograd包来实现的，autograd包会根据tensor进行过的数学运算来自动计算其对应的梯度。具体来说，torch.tensor是autograd包的基础类，如果你设置tensor的requires_grads为True，就会开始跟踪这个tensor上面的所有运算，如果你做完运算后使用tensor.backward()，所有的梯度就会自动运算，tensor的梯度将会累加到它的.grad属性里面去。更具体地说，损失函数loss是由模型的所有权重w经过一系列运算得到的，若某个w的requires_grads为True，则w的所有上层参数（后面层的权重w）的.grad_fn属性中就保存了对应的运算，然后在使用loss.backward()后，会一层层的反向传播计算每个w的梯度值，并保存到该w的.grad属性中。

**3. 多个loss分别回传：**

```python
## P1. 一个loss 回传多次 （一般不会用到）
for epoch in range(1, epochs):
    for i, (inputs, labels) in enumerate(train_loader):
        output= model(inputs)
        loss = criterion(output, labels)
        optimizer.zero_grad()  ## 先把历史梯度清零 （每次loss回传前都需要，否则会受历史batch的影响）
        loss.backward(retain_graph=True)   ## loss回传 (如果后面还需要用到这个loss的梯度，则需要设置retain_graph为True，否则loss一旦回传，计算该loss的Tensor图就会清除，下次再计算梯度就是空值了)
        loss.backward()   ## loss再次回传
        optimizer.step()  ## 参数更新  （只有进行了step才更新参数，虽然回传了两次loss（计算了两次梯度），但如果只回传了一次，则只更新了一次，而且更新的值也不变，即利用当前梯度更新）

## P2. 多个loss 分别回传 （中间无修改模型的操作，可以夹杂其他操作）
for epoch in range(1, epochs):
    for i, (inputs, labels) in enumerate(train_loader):
        output= model(inputs)
        lossA = criterionA(output, labels)
        lossB = criterionB(output, labels)
        optimizer.zero_grad()  ## 先把历史梯度清零 （每次loss回传前都需要，否则会受历史batch的影响）
        ########## 2选1 ###########
        #######  方法1  #######
        lossA.backward(retain_graph=True)   ## lossA回传 (需要设置retain_graph为True，否则和lossA相关的Tensor都会被释放，如果其中有些要用来算lossB，则lossB回传会报错)
        lossB.backward()   ## lossB回传
        optimizer.step()  ## 模型同时更新lossA和lossB计算相关的参数
        #######  方法2 （最常用）  #######
        lossC = lossA+lossB  ## 直接相加为lossC, 也可以加入权重： lossC = WA*lossA+WB*lossB
        lossC.backward()   ## lossC回传
        optimizer.step()  ## 模型更新lossC计算相关的参数（必然包含lossA和lossB计算相关的参数）
        
## P3. 多个loss 分别回传 （中间插入过渡模型相关的步骤）    
for epoch in range(1, epochs):
    for i, (inputs, labels) in enumerate(train_loader):
        output= model(inputs)
        lossA = criterionA(output, labels)
        lossB = criterionB(output, labels)
        optimizer.zero_grad()  ## 历史梯度清零 
        ########### 情景1 lossA更新模型后，再计算lossB更新模型 ###########
        lossA.backward()   ## lossA回传
        optimizer.step()  ## 模型更新lossA计算相关的参数 ==> 模型已经改变 之前计算的lossB已经失效，无法再回传了！
        output_cur= model(inputs)
        lossB_new = criterionB(output_cur, labels)  ## 重新计算lossB_new (和之前算的lossB值是不同的)
        lossB_new.backward()   ## lossB_new回传
        optimizer.step()  ## 模型更新lossB计算相关的参数  ######注意：分开更新和同时更新lossA，lossB结果是不同的！
        ########### 情景2： 需要达到lossA，lossB同时回传的效果，又需要lossA回传后的临时操作 ###########
        lossA.backward()   ## lossA回传 
        optimizer.step()  ## 模型以学习率 lr 更新 lossA 的梯度
        some_model_related_operation
        for g in optimizer.param_groups:  ## 修改学习率为之前的相反数，进而前进一步后退一步回到原始值
            g['lr'] = -g['lr']
        __some__model__related__operations__
        optimizer.step()   ## 模型以学习率 -lr 更新 lossA 的梯度-->回到原始状态 (梯度算一次就可以，没有清零就还在)
        for g in optimizer.param_groups:  ## 把学习率改回来
            g['lr'] = -g['lr']
        output_cur= model(inputs) ## 重新计算 lossA， lossB
        lossA_new = criterionA(output_cur, labels)
        lossB_new = criterionA(output_cur, labels)
        optimizer.zero_grad()
        lossA_new.backward()   ## lossA回传
        lossB_new.backward()   ## lossB回传
        optimizer.step()  ## 更新参数
        ## 理论上讲 情景2 和 P2 结果相同，但实际会有差异(why)，情景1结果和P2肯定是不同的
```



## sklearn

#### PCA结果随机

test时，利用train数据训练的PCA模型对test数据进行降维，但每次降维输出的结果不一致，最终导致每次test的AUC不一样。

原因：`svd_solver`参数设置的是 auto/random。random模式下，会进行随机的优化算法，加速PCA。auto模式会根据数据规模确定使用random模式还是full模式。

```python
class sklearn.decomposition.PCA(n_components=None, *, copy=True, whiten=False, svd_solver='auto', tol=0.0, iterated_power='auto', random_state=None)
## svd_solver 即指定奇异值分解SVD的方法，由于特征分解是奇异值分解SVD的一个特例，一般的PCA库都是基于SVD实现的。有4个可以选择的值：{‘auto’, ‘full’, ‘arpack’, ‘randomized’}。randomized一般适用于数据量大，数据维度多同时主成分数目比例又较低的PCA降维，它使用了一些加快SVD的随机算法。 full则是传统意义上的SVD，使用了scipy库对应的实现。arpack和randomized的适用场景类似，区别是randomized使用的是scikit-learn自己的SVD实现，而arpack直接使用了scipy库的sparse SVD实现。默认是auto，即PCA类会自己去在前面讲到的三种算法里面去权衡，选择一个合适的SVD算法来降维。
                           
```

解决：法1. 保存模型训练时的PCA模型 pickel.dump(pca, f)，test时直接调用pca.pkl。法2：指定使用 full 模式。

## jupyter

#### vscode进入虚拟环境py36_env后，无法识别 `jupyter notebook`命令，也无法通过`source`切换到其他环境，无法识别`source activate base`。

原因：anaconda主环境（`xxxx\anaconda3\bin`）未加入到环境变量`PATH`中。（可用 `echo $PATH`查看当前环境变量确认）

解决：

```python
## 将anaconda主环境加入PATH中
export PATH='$PATH:<path_of_anaconda_base>'
# 必须将其加入到虚拟环境路径后面，否则会导致当前terminal为显示为虚拟环境，实际新加入的在base环境中
# export PATH='<path_of_anaconda_base>:$PATH' 会导致将新加入的路径加到PATH最前面，这样运行Python xxx 就用的是新加入的base Python
```





