---
layout: post
title: 值得记录的bug们
date: 2020-12-31
tag: 持续更新
---



## 值得记录的bug们

## pytorch

#### MSE计算

dataloader的标签（float数值）需要转成float形式。

- eg:

  ``` python
  age_label = item['age_label'].to(device).long()  ## wrong
  age_label = item['age_label'].to(device).float()  ## right
  ```

  

  

#### debug时，dataloader的num_workers需要设置为0，否则多线程导致无法调试。





## sklearn

#### PCA结果随机

test时，利用train数据训练的PCA模型对test数据进行降维，但每次降维输出的结果不一致，最终导致每次test的AUC不一样。

原因：`svd_solver`参数设置的是 auto/random。random模式下，会进行随机的优化算法，加速PCA。auto模式会根据数据规模确定使用random模式还是full模式。

```python
class sklearn.decomposition.PCA(n_components=None, *, copy=True, whiten=False, svd_solver='auto', tol=0.0, iterated_power='auto', random_state=None)
## svd_solver 即指定奇异值分解SVD的方法，由于特征分解是奇异值分解SVD的一个特例，一般的PCA库都是基于SVD实现的。有4个可以选择的值：{‘auto’, ‘full’, ‘arpack’, ‘randomized’}。randomized一般适用于数据量大，数据维度多同时主成分数目比例又较低的PCA降维，它使用了一些加快SVD的随机算法。 full则是传统意义上的SVD，使用了scipy库对应的实现。arpack和randomized的适用场景类似，区别是randomized使用的是scikit-learn自己的SVD实现，而arpack直接使用了scipy库的sparse SVD实现。默认是auto，即PCA类会自己去在前面讲到的三种算法里面去权衡，选择一个合适的SVD算法来降维。
                           
```

解决：法1. 保存模型训练时的PCA模型 pickel.dump(pca, f)，test时直接调用pca.pkl。法2：指定使用 full 模式。

## jupyter

#### vscode进入虚拟环境py36_env后，无法识别 `jupyter notebook`命令，也无法通过`source`切换到其他环境，无法识别`source activate base`。

原因：anaconda主环境（`xxxx\anaconda3\bin`）未加入到环境变量`PATH`中。（可用 `echo $PATH`查看当前环境变量确认）

解决：

```python
## 将anaconda主环境加入PATH中
export PATH='$PATH:<path_of_anaconda_base>'
# 必须将其加入到虚拟环境路径后面，否则会导致当前terminal为显示为虚拟环境，实际新加入的在base环境中
# export PATH='<path_of_anaconda_base>:$PATH' 会导致将新加入的路径加到PATH最前面，这样运行Python xxx 就用的是新加入的base Python
```





## pandas

#### **df.iloc VS df.loc** 

df.iloc[1:3, :]  : 取第1行~第2行 （不包含第3行）   .iloc按位置取切片，操作和list切片操作一致，取左不取右

df.loc[1:3, :] ：取index=1,2,3的行 （包含index=3的行）   .loc表示按index的**内容**去取！！！ 左右都取



#### **pd.concat(),  df.append(), df.loc[i]  VS  np.append()   VS   ls.append() 速度问题**

numpy 不支持动态扩展！！！ 每次进行append 会重新分配内存，复制原来的array过来。因此 多次进行append的时候会很慢，越append越慢，非常慢！！

pandas存在和numpy同样的问题！但实际比numpy会快一些（why?) ，即使如此也非常慢！

**当要进行多次append的时候，请使用list， 支持动态扩展，速度很快！**

三者运行时长： numpy >> pandas >> list  （相差非常多！ 百倍）

**numpy适合矩阵运算**，numpy的广播矩阵运算会远远快于lIst的嵌套for循环（百倍）