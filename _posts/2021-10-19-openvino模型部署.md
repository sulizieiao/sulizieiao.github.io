---
layout: post
title: pytorch-->openvino模型部署
date: 2021-10-19 
tag: 技术
---

## pytorch 转 openvino部署

### step1： pytorch转onnx

试用pytorch自带的 torch.onnx.export()函数即可。

```python
#  转换代码示例 (网络有多个输入：input_1, input_2)
import torch
import model_backbone   ## 导入模型结构定义
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

def pytorch_model_init(model_path): ##加载pytorch模型
    checkpoint = torch.load(model_path, map_location=device)
    model = model_backbone().to(device)
    model.load_state_dict(checkpoint['model_state_dict']) ## 需要查看checkpoint的keys，确认参数的键
    return model
def convert_ONNX(input_pth_path, output_onnx_path):
    model = pytorch_model_init(input_pth_path)
    model.eval()
    input_1 = torch.randn(1,3,64,64,requires_grad=True).to(device)  ## 模型模拟输入 1: 3*64*64
    input_2 = torch.randn(1,20,requires_grad=True).to(device)  ## 模型模拟输入 2: 1*20
    dummy_input = (input_1, input_2)
    torch.onnx.export(model, dummy_input, output_onnx_path, 
                      input_names=['input_1', 'input_2'], output_names=['output'],
                      opset_version=12,verbose=True)  ## opset_version:设置onnx的版本，verbose：是否输出过程

if __name__ == '__main__':
    input_pth_path = '..../pytorch_trained_model.pth'
    output_onnx_path = '..../xxxNet_model.onnx'
    convert_ONNX(input_pth_path, output_onnx_path)
```

### step 2： onnx 转 openvino

在**已经安装好openvino的环境**下：直接Python mo_onnx.py进行转换。参数设置参考：[converting model general](https://docs.openvino.ai/2018_R5/_docs_MO_DG_prepare_model_convert_model_Converting_Model_General.html)

`python /opt/intel/openvino_2021/deployment_tools/model_optimizer/mo_onnx.py --input_model xxxNet_model.onnx --input_shape [1,3,64,64],[1,20] --input input_1,input_2 --output output `

注意：有多个输入时，需要使用--input依次指明输入名称

### step 3： 编写openvino模型调用接口

```python
from openvino.inference_engine import IECore

## 模型加载
def model_init(model_path):
    model_xml = model_path + '.xml'
    model_bin = model_path + '.bin'
    config_user_specified = {'CPU_THREADS_NUM': '2'}  ## 配置参数
    ie = IECore()
    net = ie.read_network(model=model_xml, weights=model_bin)
    model = ie.load_network(network=net, device_name='CPU', config=config_user_specified)
    
## 模型预测    
def model_prediction(model, input_1, input_2):
    input_1, input_2 = input_preprocess(input_1, input_2)  ## 输入预处理： eg: image_transform...
    input_dict = {'input_1': input_1, 'input_2': input_2}
    res = model.infer(input_dict)
    pre_score = res['output'][0][1]  ## 以二分类为例
    return pre_score
```

